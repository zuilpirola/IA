{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte I. Busca\n",
    "\n",
    "## Pergunta 1.\n",
    "\n",
    "Dado o seguinte esqueleto de código em Python para a implementação dos algoritmos de Pesquisa em Profundidade (Depth First Search, DFS) e Pesquisa em Largura (Breadth First, BFS):\n",
    "\n",
    "a. Complete as partes em falta, identificadas com comentários 3pt  \n",
    "b. Certifique-se de que as funções dfs e bfs funcionam corretamente para um grafo exemplo criado por si representado por um dicionário de adjacências através com a função `adicionar_aresta`  2pt  \n",
    "c. Este código implementa um método diferente, mas totalmente equivalente, para evitar `loops` ao que explicamos nas aulas. explique este método em detalhe 3pt  \n",
    "\n",
    "**Nota:**\n",
    "\n",
    "Este código é uma implementação parcial dos métodos de busca não informada focada nos percursos DFS e BFS. Note que para esta pergunta não é necessário incluir a verificação de termos chegado ao estado objetivo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esqueleto para DFS e BFS\n",
    "\n",
    "def adicionar_aresta(grafo, vertice, aresta):\n",
    "    if vertice not in grafo:\n",
    "        grafo[vertice] = []\n",
    "    grafo[vertice].append(aresta)\n",
    "\n",
    "def dfs(grafo, inicio):\n",
    "    visitados = set()\n",
    "    pilha = [inicio]\n",
    "    \n",
    "    while pilha:\n",
    "        vertice = # completar aqui \n",
    "        if vertice not in visitados:\n",
    "            print(vertice, end=\" \")\n",
    "            visitados.add(vertice)\n",
    "            # Adicionar os vizinhos do vertice na pilha\n",
    "\n",
    "\n",
    "def bfs(grafo, inicio):\n",
    "    visitados = set()\n",
    "    fila = [inicio]\n",
    "    \n",
    "    while fila:\n",
    "        vertice = # completar aqui \n",
    "        if vertice not in visitados:\n",
    "            print(vertice, end=\" \")\n",
    "            visitados.add(vertice)\n",
    "            # Adicionar os vizinhos do vertice na fila\n",
    "\n",
    "\n",
    "# Exemplo de uso\n",
    "grafo = {}\n",
    "# completar a adição de nós e arestas. Nós devem ser letras em maiuscula, e estado inicial deve ser sempre 'A'.\n",
    "\n",
    "print(\"DFS:\")\n",
    "dfs(grafo, 'A')\n",
    "print(\"\\nBFS:\")\n",
    "bfs(grafo, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta 2\n",
    "\n",
    "Faça uma cópia do código implementado na pergunta 1, e edite para que as funções de busca recebam o estado objetivo como parâmetro, e que as mesmas terminem quando este estado seja encontrado 2pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte II: NLP\n",
    "\n",
    "## Pergunta 1\n",
    "\n",
    "5pt \n",
    "\n",
    "a. Carregar of ficheiros `corpus_1.txt` and `corpus_2.txt` os quais são corpora, um documento por cada linha, que termina com ponto.  \n",
    "b. Escrever uma função em Python que devolva o tamanho do vocabulário de cada corpus, sem qualquer preprocessamento (sem remoção de stop words, lematização, etc.)  exepto remoção dos \".\" no final de cada documento  \n",
    "c. Utilize o código embaixo para preprocessar o corpus, este preprocessamento será unicamente tokenizar e remover stop words  \n",
    "d. Calcule o IDF do vocabulario do corpus depois do preprocessamento, faça analise exploratória dos valores para diferentes termos. Identifique um conjunto dos termos mais informativos para cada corpus, justifique a sua resposta  \n",
    "e. Compare os dois corpora e faça uma analise descritiva do seu conteúdo com suporte nos valores IDF \n",
    "\n",
    "A fórmula do IDF é:\n",
    "\n",
    "$$IDF(w) = \\log \\left( \\frac{N}{df(w)} \\right)$$\n",
    "\n",
    "A função `log` foi importada através de importar `math` (ver imports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manuel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Baixar o recurso 'stopwords' se ainda não tiver sido baixado\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Obter as stop words em português\n",
    "stop_words_pt = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pergunta 2\n",
    "\n",
    "\n",
    "(a) Usando código Python, faça uma seleção aleatória de cinco documentos no corpus_1 e calcule a similaridade de cosseno entre todos os pares de documentos, repeter o procedimento para o corpus_2. Que tão variaveis (de forma analitica exploratória) são os valores obtidos para cada corpus?  \n",
    "\n",
    "(b) Escreva código Python que selecione um documento aleatório de cada um dos corpora e calcule a similaridade de cosseno entre os documentos. Repeter o procedimento dez vezes. Considerando os resultados obtidos em (b) e comparando com (a), o que consegue concluir (se alguma coisa) sobre a natureza dos dois corpora?  \n",
    "\n",
    "A formula para similaridade de cosseno:\n",
    "\n",
    "$$\n",
    "\\text{similaridade cosseno} = \\cos(\\theta) = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}\n",
    "$$\n",
    "\n",
    "5pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
